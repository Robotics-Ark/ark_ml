name: sb3_rl
model:
  name: sb3_dummy        # placeholder

env:
  # Any ArkEnv subclass; for Franka:
  class_path: "arkml.core.rl.franka_env.FrankaPickPlaceEnv"
  num_envs: 2
  kwargs:
    max_steps: 200
    config_path: "ark_diffusion_policies_on_franka/diffusion_policy/config/global_config.yaml" #${global_config}   # same config used elsewhere
    channel_schema: "ark_framework/ark/configs/franka_panda.yaml" #${channel_schema}
    asynchronous: False
    sim: True

sb3:
  algo_name: "ppo"        # "ppo", "sac", "td3", "ddpg"
  policy: "MultiInputPolicy"
  total_timesteps: 100000
  eval_episodes: 5
  # Optional action smoothing (exponential moving average) applied before sending to the robot
  action_smoothing:
    alpha: 0.3          # 0.0 disables smoothing, closer to 1.0 follows the policy more closely
    clip_delta: 0.05    # per-dimension max change after smoothing; set null to disable clipping
  kwargs:                 # passed directly to SB3 algo ctor
    learning_rate: 3.0e-4
    gamma: 0.99
